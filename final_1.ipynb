{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irD2VAE2e28U",
        "outputId": "86f69fea-3806-4813-e616-94e3d5bcd1b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Robust Processing & Saving to /content/drive/MyDrive/final_data ---\n",
            "Found 7428 images. Starting pipeline...\n",
            "Processed 200 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 400 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 600 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 800 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 1000 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 1200 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 1400 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 1600 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 1800 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 2000 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 2200 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 2400 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 2600 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 2800 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 3000 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 3200 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 3400 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 3600 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 3800 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 4000 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 4200 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 4400 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 4600 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 4800 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 5000 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 5200 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 5400 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 5600 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 5800 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 6000 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 6200 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 6400 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 6600 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 6800 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n",
            "Processed 7000 images... (Fractured Split Stats: {'train': 0, 'val': 0})\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# path_configuting_for _images\n",
        "DATASET_PATH = '/content/drive/MyDrive/Pre_processed_data-20260110T003759Z-1-001'\n",
        "OUTPUT_PATH = '/content/drive/MyDrive/final_data'\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# splitting_configuration\n",
        "CREATE_VAL_SPLIT_FOR = ['Fractured']\n",
        "VAL_SPLIT_RATIO = 0.2  # 20% of training data will be moved to validation\n",
        "\n",
        "# --- 1. CORE MEDICAL FILTERING LOGIC (OpenCV) ---\n",
        "def apply_medical_filters_and_resize(image_array):\n",
        "    \"\"\"\n",
        "    ROBUST PIPELINE:\n",
        "    1. Convert to uint8\n",
        "    2. Apply Filters on HIGH-RES image (Preserves Detail)\n",
        "    3. Resize to 224x224 (Reduces Size)\n",
        "    \"\"\"\n",
        "    # 1. Convert Tensor to Numpy\n",
        "    img = image_array.astype(np.uint8)\n",
        "\n",
        "    # Check if image loaded correctly\n",
        "    if img is None or img.size == 0:\n",
        "        return np.zeros((IMG_SIZE[0], IMG_SIZE[1], 3), dtype=np.float32)\n",
        "\n",
        "    # 2. Medical Filtering (High Resolution)\n",
        "    # Convert to LAB\n",
        "    try:\n",
        "        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "\n",
        "        # CLAHE (Contrast Enhancement)\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "        l = clahe.apply(l)\n",
        "\n",
        "        # Merge back\n",
        "        lab = cv2.merge((l, a, b))\n",
        "        img_clahe = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "        # Gaussian Blur (Denoising)\n",
        "        img_filtered = cv2.GaussianBlur(img_clahe, (3, 3), 0)\n",
        "    except Exception:\n",
        "        # Fallback if image format is weird\n",
        "        img_filtered = img\n",
        "\n",
        "    # 3. Resize to Target Size (224x224)\n",
        "    img_resized = cv2.resize(img_filtered, IMG_SIZE)\n",
        "\n",
        "    return img_resized.astype(np.float32)\n",
        "\n",
        "#\n",
        "def tf_preprocess_wrapper(image, label):\n",
        "    \"\"\"\n",
        "    Wraps the OpenCV logic and applies MobileNet Normalization.\n",
        "    \"\"\"\n",
        "    # 1. Run Python Logic (Filter + Resize)\n",
        "    [processed_img] = tf.numpy_function(apply_medical_filters_and_resize, [image], [tf.float32])\n",
        "\n",
        "    # 2. Enforce Shape (Required by TensorFlow)\n",
        "    processed_img.set_shape([IMG_SIZE[0], IMG_SIZE[1], 3])\n",
        "\n",
        "    # 3. Intensity Normalization (MobileNet Standard: -1 to 1)\n",
        "    final_img = tf.keras.applications.mobilenet_v3.preprocess_input(processed_img)\n",
        "\n",
        "    return final_img, label\n",
        "\n",
        "# --- 3. DATASET BUILDER (Updated for 4 Classes) ---\n",
        "def get_preprocessed_dataset(subset_name='train'):\n",
        "    directory = os.path.join(OUTPUT_PATH, subset_name)\n",
        "    if not os.path.exists(directory):\n",
        "        # Fallback to source if output doesn't exist yet (for testing)\n",
        "        directory = os.path.join(DATASET_PATH, subset_name)\n",
        "        if not os.path.exists(directory):\n",
        "             raise FileNotFoundError(f\"Directory not found: {directory}\")\n",
        "\n",
        "    print(f\"Loading {subset_name} data from: {directory}\")\n",
        "\n",
        "    # A. Load WITHOUT resizing or batching first\n",
        "    ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        directory,\n",
        "        labels='inferred',\n",
        "        # UPDATED: Use 'categorical' for 4 classes (Normal, Pneumonia, Fractured, Other)\n",
        "        # Use 'int' if you prefer sparse integers (0, 1, 2, 3)\n",
        "        label_mode='categorical',\n",
        "        class_names=None, # Auto-detects all folders present\n",
        "        image_size=None, # Load Original Size\n",
        "        batch_size=None, # No batching yet\n",
        "        shuffle=(subset_name == 'train')\n",
        "    )\n",
        "\n",
        "    # B. Apply Filter -> Resize -> Normalize\n",
        "    ds = ds.map(tf_preprocess_wrapper, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # C. Batch and Optimize\n",
        "    ds = ds.batch(BATCH_SIZE)\n",
        "    ds = ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    return ds\n",
        "\n",
        "# --- 4. SAVE TO DISK FUNCTION (With Auto-Split for Fractured) ---\n",
        "def process_and_save_to_disk(output_dir=OUTPUT_PATH):\n",
        "    \"\"\"\n",
        "    Reads from DATASET_PATH.\n",
        "    Applies filters.\n",
        "    Saves to OUTPUT_PATH.\n",
        "    automatically moves 20% of 'Fractured' training images to 'val' folder.\n",
        "    \"\"\"\n",
        "    src_path = Path(DATASET_PATH)\n",
        "    dst_path = Path(output_dir)\n",
        "\n",
        "    print(f\"\\n--- Robust Processing & Saving to {dst_path} ---\")\n",
        "\n",
        "    if not src_path.exists():\n",
        "        print(f\"Error: Source {src_path} does not exist.\")\n",
        "        return\n",
        "\n",
        "    # Get all PNG/JPG images recursively\n",
        "    image_files = list(src_path.rglob('*.[pjPJ][nNpP][gG]*')) # Matches .png, .jpg, .jpeg\n",
        "    print(f\"Found {len(image_files)} images. Starting pipeline...\")\n",
        "\n",
        "    count = 0\n",
        "    split_counts = {'train': 0, 'val': 0}\n",
        "\n",
        "    for img_path in image_files:\n",
        "        # 1. Identify Structure\n",
        "        # Expected structure: DATASET_PATH / subset / class / image.png\n",
        "        relative_path = img_path.relative_to(src_path)\n",
        "        parts = relative_path.parts\n",
        "\n",
        "        # Skip 'masks' folder\n",
        "        if 'masks' in str(relative_path).lower():\n",
        "            continue\n",
        "\n",
        "        # Determine subset (train/val/test) and class name\n",
        "        if len(parts) >= 2:\n",
        "            subset = parts[0]      # e.g., 'train'\n",
        "            class_name = parts[1]  # e.g., 'Fractured'\n",
        "        else:\n",
        "            continue # Skip files in root\n",
        "\n",
        "        # 2. Split Logic for 'Fractured' Class\n",
        "        # If image is in 'train' and belongs to 'Fractured', randomly move to 'val'\n",
        "        target_subset = subset\n",
        "\n",
        "        if subset == 'train' and class_name in CREATE_VAL_SPLIT_FOR:\n",
        "            if random.random() < VAL_SPLIT_RATIO:\n",
        "                target_subset = 'val'\n",
        "                split_counts['val'] += 1\n",
        "            else:\n",
        "                split_counts['train'] += 1\n",
        "\n",
        "        # Construct new relative path\n",
        "        # Replace original subset (e.g. 'train') with target_subset (e.g. 'val')\n",
        "        new_parts = list(parts)\n",
        "        new_parts[0] = target_subset\n",
        "        new_relative_path = Path(*new_parts)\n",
        "\n",
        "        save_path = dst_path / new_relative_path\n",
        "\n",
        "        # Create the directory (Make the folder)\n",
        "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # 3. Read Image (High Res)\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        # 4. Convert BGR to RGB\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # 5. Apply Robust Logic (Filter High-Res -> Resize)\n",
        "        processed_array = apply_medical_filters_and_resize(img_rgb)\n",
        "\n",
        "        # 6. Save\n",
        "        save_img = np.clip(processed_array, 0, 255).astype(np.uint8)\n",
        "        save_img_bgr = cv2.cvtColor(save_img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        cv2.imwrite(str(save_path), save_img_bgr)\n",
        "        count += 1\n",
        "\n",
        "        if count % 200 == 0:\n",
        "            print(f\"Processed {count} images... (Fractured Split Stats: {split_counts})\")\n",
        "\n",
        "    print(f\"\\nSuccess! {count} images fully processed.\")\n",
        "    print(f\"Auto-split statistics for {CREATE_VAL_SPLIT_FOR}: {split_counts}\")\n",
        "    print(f\"Data saved to: {dst_path}\")\n",
        "    print(\"Folder structure is now ready for 4-class classification.\")\n",
        "\n",
        "# --- 5. EXECUTION ---\n",
        "if __name__ == \"__main__\":\n",
        "    process_and_save_to_disk()\n",
        "\n",
        "    # Optional: Verify dataset loading\n",
        "    try:\n",
        "        print(\"\\nVerifying Dataset Loading...\")\n",
        "        # Point to the NEW output path\n",
        "        test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "            os.path.join(OUTPUT_PATH, 'train'),\n",
        "            labels='inferred',\n",
        "            label_mode='categorical'\n",
        "        )\n",
        "        print(\"Classes detected:\", test_ds.class_names)\n",
        "    except Exception as e:\n",
        "        print(f\"Verification skipped (Data might not be ready): {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras import layers, models, regularizers, callbacks\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "# Ensure this path matches your drive structure\n",
        "LOCAL_DATASET_PATH = '/content/drive/MyDrive/final_data/Pre_processed_data'\n",
        "INPUT_SHAPE = (224, 224, 3)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-4\n",
        "EPOCHS =25\n",
        "\n",
        "# --- 2. DATA LOADING WITH CRASH FIX ---\n",
        "if not os.path.exists(LOCAL_DATASET_PATH):\n",
        "    raise FileNotFoundError(f\"Dataset not found at {LOCAL_DATASET_PATH}\")\n",
        "\n",
        "def load_dataset(subset, explicit_class_names=None):\n",
        "    directory = os.path.join(LOCAL_DATASET_PATH, subset)\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        print(f\"Creating directory: {directory}\")\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    # --- THE FIX FOR THE VALUE ERROR ---\n",
        "    # If we are loading 'val' and we expect specific classes (e.g. Tuberculosis),\n",
        "    # we must ensure those folders exist, even if they are empty.\n",
        "    if explicit_class_names:\n",
        "        for class_name in explicit_class_names:\n",
        "            class_path = os.path.join(directory, class_name)\n",
        "            if not os.path.exists(class_path):\n",
        "                print(f\"‚ö†Ô∏è Fixing missing folder in {subset}: {class_name}\")\n",
        "                os.makedirs(class_path, exist_ok=True)\n",
        "    # -----------------------------------\n",
        "\n",
        "    raw_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        directory,\n",
        "        image_size=(INPUT_SHAPE[0], INPUT_SHAPE[1]),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        label_mode='categorical',\n",
        "        shuffle=(subset == 'train'),\n",
        "        class_names=explicit_class_names\n",
        "    )\n",
        "\n",
        "    # Normalize MobileNetV3 (expects -1 to 1)\n",
        "    norm_layer = tf.keras.applications.mobilenet_v3.preprocess_input\n",
        "    ds = raw_ds.map(lambda x, y: (norm_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    return ds.cache().prefetch(tf.data.AUTOTUNE), raw_ds.class_names\n",
        "\n",
        "# 1. Load Train FIRST to find the true classes\n",
        "print(\"--- Loading Training Data ---\")\n",
        "train_ds, class_names = load_dataset('train')\n",
        "print(f\" Training Classes Found: {class_names}\")\n",
        "\n",
        "# 2. Load Val using the EXACT SAME class list\n",
        "# This prevents the mismatch error by forcing the same structure\n",
        "print(\"--- Loading Validation Data ---\")\n",
        "val_ds, _ = load_dataset('val', explicit_class_names=class_names)\n",
        "\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "# --- 3. MODEL ARCHITECTURE ---\n",
        "data_augmentation = models.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.15),\n",
        "    layers.RandomZoom(0.1),\n",
        "], name=\"augmentation\")\n",
        "\n",
        "def build_model(num_classes):\n",
        "    inputs = layers.Input(shape=INPUT_SHAPE)\n",
        "    x = data_augmentation(inputs)\n",
        "\n",
        "    # MobileNetV3Large\n",
        "    base_model = MobileNetV3Large(\n",
        "        input_shape=INPUT_SHAPE,\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    base_model.trainable = True\n",
        "\n",
        "    # Freeze bottom layers to stabilize training\n",
        "    for layer in base_model.layers[:-40]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model(x, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    x = layers.Dropout(0.4)(x) # Reduced dropout slightly\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
        "    return models.Model(inputs, outputs, name=\"Medical_MobileNetV3\")\n",
        "\n",
        "model = build_model(NUM_CLASSES)\n",
        "\n",
        "# --- 4. TRAINING ---\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks_list = [\n",
        "    callbacks.ModelCheckpoint('best_model_1.keras', save_best_only=True, monitor='val_accuracy', mode='max'),\n",
        "    callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "print(f\"\\n Starting training for classes: {class_names}\")\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks_list\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYC-v1uA0vOX",
        "outputId": "42d465e9-c105-4c2a-a729-247dee8eb10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading Training Data ---\n",
            "Found 4876 files belonging to 4 classes.\n",
            "‚úÖ Training Classes Found: ['Fractured', 'Normal', 'Pneumonia', 'Tuberculosis']\n",
            "--- Loading Validation Data ---\n",
            "Found 276 files belonging to 4 classes.\n",
            "\n",
            "üöÄ Starting training for classes: ['Fractured', 'Normal', 'Pneumonia', 'Tuberculosis']\n",
            "Epoch 1/25\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 184ms/step - accuracy: 0.4876 - loss: 1.4395 - val_accuracy: 0.7391 - val_loss: 0.6962\n",
            "Epoch 2/25\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - accuracy: 0.7214 - loss: 0.6804 - val_accuracy: 0.7319 - val_loss: 0.7287\n",
            "Epoch 3/25\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - accuracy: 0.7471 - loss: 0.6013 - val_accuracy: 0.7174 - val_loss: 0.8102\n",
            "Epoch 4/25\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.7598 - loss: 0.5219 - val_accuracy: 0.7681 - val_loss: 0.6831\n",
            "Epoch 5/25\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.7770 - loss: 0.4851 - val_accuracy: 0.6957 - val_loss: 0.8497\n",
            "Epoch 6/25\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - accuracy: 0.7677 - loss: 0.4885 - val_accuracy: 0.7101 - val_loss: 0.8072\n",
            "Epoch 7/25\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 69ms/step - accuracy: 0.7915 - loss: 0.4320 - val_accuracy: 0.7500 - val_loss: 0.6862\n",
            "Epoch 8/25\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - accuracy: 0.7862 - loss: 0.4405 - val_accuracy: 0.6884 - val_loss: 0.8762\n",
            "Epoch 9/25\n",
            "\u001b[1m153/153\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - accuracy: 0.7958 - loss: 0.4103 - val_accuracy: 0.7138 - val_loss: 0.7850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "MODEL_PATH = 'best_model_1.keras' # Ensure this matches the saved name\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "# ‚úÖ CORRECTED CLASS LIST\n",
        "# Based on your training logs, you only have 3 classes.\n",
        "# The order MUST be alphabetical as per TensorFlow's default behavior.\n",
        "CLASS_NAMES = ['Fractured', 'Normal', 'Pneumonia', 'Tuberculosis']\n",
        "\n",
        "# --- LOAD MODEL ---\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    print(f\" Model not found: {MODEL_PATH}\")\n",
        "    exit()\n",
        "\n",
        "model = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "# --- PREDICTION FUNCTION ---\n",
        "def predict_image(image_path):\n",
        "    if not os.path.exists(image_path):\n",
        "        print(\" Image file not found.\")\n",
        "        return\n",
        "\n",
        "    # 1. Load and Preprocess\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None: return\n",
        "\n",
        "    # To resize image.\n",
        "    img_resized = cv2.resize(img, IMG_SIZE)\n",
        "\n",
        "    # Convert to RGB and Preprocess for MobileNetV3\n",
        "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "    img_array = img_rgb.astype(np.float32)\n",
        "    img_preprocessed = tf.keras.applications.mobilenet_v3.preprocess_input(img_array)\n",
        "\n",
        "    # Add batch dimension\n",
        "    img_batch = np.expand_dims(img_preprocessed, axis=0)\n",
        "\n",
        "    # 2. Predict\n",
        "    predictions = model.predict(img_batch, verbose=0)[0]\n",
        "    predicted_index = np.argmax(predictions)\n",
        "    confidence = predictions[predicted_index] * 100\n",
        "\n",
        "    result_label = CLASS_NAMES[predicted_index]\n",
        "\n",
        "    # 3. Output\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"Input: {os.path.basename(image_path)}\")\n",
        "    if result_label == \"Normal\":\n",
        "        print(f\" Prediction: {result_label} ({confidence:.2f}%)\")\n",
        "    else:\n",
        "        print(f\" Prediction: {result_label} DETECTED ({confidence:.2f}%)\")\n",
        "\n",
        "    print(\"\\nConfidence Breakdown:\")\n",
        "    for i, score in enumerate(predictions):\n",
        "        print(f\"  - {CLASS_NAMES[i]}: {score*100:.2f}%\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"Loaded Model for classes: {CLASS_NAMES}\")\n",
        "    while True:\n",
        "        path = input(\"\\nEnter image path (or 'q' to quit): \").strip().strip('\"').strip(\"'\")\n",
        "        if path.lower() == 'q': break\n",
        "        predict_image(path)"
      ],
      "metadata": {
        "id": "ROPgIQAG7vga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ns-PZgN1gDVx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}